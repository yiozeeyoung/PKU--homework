{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc968cf0",
   "metadata": {},
   "source": [
    "# Problem 3: 贝叶斯优化反应收率预测\n",
    "\n",
    "本notebook使用反应数据集B（Doyle数据集）实现贝叶斯优化来预测和优化反应收率。\n",
    "\n",
    "**学生ID: 153**  \n",
    "**随机种子: 1153, 2153, 3153, 4153, 5153**\n",
    "\n",
    "## 目标\n",
    "- 使用高斯过程回归器建立反应收率预测模型\n",
    "- 实现期望改进(EI)和上置信界(UCB)获取函数\n",
    "- 通过贝叶斯优化循环寻找最优反应条件\n",
    "- 分析优化进度和收敛性\n",
    "- 提供化学意义的解释"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fff0735",
   "metadata": {},
   "source": [
    "## 1. 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "489c2a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 所有库导入成功\n",
      "✓ 随机种子设置: [1153, 2153, 3153, 4153, 5153]\n",
      "✓ 主要种子: 1153\n"
     ]
    }
   ],
   "source": [
    "# 导入基础库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 导入机器学习相关库\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, WhiteKernel, ConstantKernel\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# 导入化学信息学库\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, rdMolDescriptors\n",
    "from rdkit.Chem.rdMolDescriptors import GetMorganFingerprintAsBitVect\n",
    "\n",
    "# 设置随机种子（基于学生ID: 153）\n",
    "RANDOM_SEEDS = [1153, 2153, 3153, 4153, 5153]\n",
    "MAIN_SEED = 1153\n",
    "\n",
    "np.random.seed(MAIN_SEED)\n",
    "\n",
    "# 设置图形参数\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"✓ 所有库导入成功\")\n",
    "print(f\"✓ 随机种子设置: {RANDOM_SEEDS}\")\n",
    "print(f\"✓ 主要种子: {MAIN_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a656f285",
   "metadata": {},
   "source": [
    "## 2. 加载Doyle数据集（反应数据集B）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5090c9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 成功加载数据集，形状: (3955, 5)\n",
      "✓ 列名: ['Ligand', 'Additive', 'Base', 'Aryl halide', 'Target']\n",
      "\n",
      "数据集基本信息:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3955 entries, 0 to 3954\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Ligand       3955 non-null   object \n",
      " 1   Additive     3955 non-null   object \n",
      " 2   Base         3955 non-null   object \n",
      " 3   Aryl halide  3955 non-null   object \n",
      " 4   Target       3955 non-null   float64\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 154.6+ KB\n",
      "None\n",
      "\n",
      "前5行数据:\n",
      "                                              Ligand           Additive  \\\n",
      "0  CC(C)C(C=C(C(C)C)C=C1C(C)C)=C1C2=C(P([C@@]3(C[...      CC1=CC(C)=NO1   \n",
      "1  CC(C)C(C=C(C(C)C)C=C1C(C)C)=C1C2=C(P([C@@]3(C[...   O=C(OC)C1=CC=NO1   \n",
      "2  CC(C)C(C=C(C(C)C)C=C1C(C)C)=C1C2=C(P(C3CCCCC3)...   O=C(OC)C1=CC=NO1   \n",
      "3  CC(C)C(C=C(C(C)C)C=C1C(C)C)=C1C2=C(P(C(C)(C)C)...  CCOC(C1=CON=C1)=O   \n",
      "4  CC(C)C(C=C(C(C)C)C=C1C(C)C)=C1C2=C(P([C@@]3(C[...      CC1=CC(C)=NO1   \n",
      "\n",
      "                                        Base              Aryl halide  \\\n",
      "0  CN(C)P(N(C)C)(N(C)C)=NP(N(C)C)(N(C)C)=NCC            ClC1=NC=CC=C1   \n",
      "1  CN(C)P(N(C)C)(N(C)C)=NP(N(C)C)(N(C)C)=NCC            BrC1=NC=CC=C1   \n",
      "2  CN(C)P(N(C)C)(N(C)C)=NP(N(C)C)(N(C)C)=NCC         IC1=CC=C(CC)C=C1   \n",
      "3                           CN1CCCN2C1=NCCC2  ClC1=CC=C(C(F)(F)F)C=C1   \n",
      "4                           CN1CCCN2C1=NCCC2        ClC1=CC=C(OC)C=C1   \n",
      "\n",
      "      Target  \n",
      "0  70.410458  \n",
      "1  11.064457  \n",
      "2  10.223550  \n",
      "3  20.083383  \n",
      "4   0.492663  \n",
      "\n",
      "缺失值统计:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "✓ 数据集包含 3955 个反应\n",
      "✓ 收率统计信息:\n",
      "count    3955.000000\n",
      "mean       33.085259\n",
      "std        27.291205\n",
      "min         0.000000\n",
      "25%         7.877560\n",
      "50%        28.761729\n",
      "75%        53.278687\n",
      "max        99.999990\n",
      "Name: Target, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 收率范围: 0.0% - 100.0%\n",
      "✓ 平均收率: 33.1%\n",
      "✓ 收率标准差: 27.3%\n"
     ]
    }
   ],
   "source": [
    "def load_doyle_dataset(file_path):\n",
    "    \"\"\"\n",
    "    从datasets/Reaction_Dataset_B.csv加载Doyle数据集\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"✓ 成功加载数据集，形状: {df.shape}\")\n",
    "        print(f\"✓ 列名: {list(df.columns)}\")\n",
    "        \n",
    "        # 显示基本信息\n",
    "        print(\"\\n数据集基本信息:\")\n",
    "        print(df.info())\n",
    "        \n",
    "        # 显示前几行数据\n",
    "        print(\"\\n前5行数据:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        # 检查缺失值\n",
    "        missing_values = df.isnull().sum()\n",
    "        print(f\"\\n缺失值统计:\")\n",
    "        print(missing_values[missing_values > 0])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"✗ 加载数据失败: {e}\")\n",
    "        return None\n",
    "\n",
    "# 加载Doyle数据集\n",
    "doyle_data = load_doyle_dataset('dataset/Reaction Dataset B.csv')\n",
    "\n",
    "if doyle_data is not None:\n",
    "    print(f\"\\n✓ 数据集包含 {len(doyle_data)} 个反应\")\n",
    "    \n",
    "    # 分析目标变量（收率）\n",
    "    if 'Target' in doyle_data.columns:\n",
    "        print(f\"✓ 收率统计信息:\")\n",
    "        print(doyle_data['Target'].describe())\n",
    "        \n",
    "        # 收率分布可视化\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.hist(doyle_data['Target'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        plt.xlabel('反应收率 (%)')\n",
    "        plt.ylabel('频次')\n",
    "        plt.title('反应收率分布')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.boxplot(doyle_data['Target'])\n",
    "        plt.ylabel('反应收率 (%)')\n",
    "        plt.title('反应收率箱线图')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"✓ 收率范围: {doyle_data['Target'].min():.1f}% - {doyle_data['Target'].max():.1f}%\")\n",
    "        print(f\"✓ 平均收率: {doyle_data['Target'].mean():.1f}%\")\n",
    "        print(f\"✓ 收率标准差: {doyle_data['Target'].std():.1f}%\")\n",
    "    else:\n",
    "        print(\"✗ 未找到收率列，请检查数据格式\")\n",
    "        \n",
    "# 贝叶斯优化过程可视化（假设有相关数据）\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(optimization_results['Iteration'], optimization_results['Yield'], marker='o', linestyle='-')\n",
    "plt.title('Bayesian Optimization Progress') # 原为中文\n",
    "plt.xlabel('Iteration') # 原为中文\n",
    "plt.ylabel('Yield') # 原为中文\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324c7860",
   "metadata": {},
   "source": [
    "## 3. 特征预处理和编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2161000a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数值特征 (0): []\n",
      "分类特征 (4): ['Ligand', 'Additive', 'Base', 'Aryl halide']\n",
      "✓ Ligand: 4 个类别\n",
      "✓ Additive: 22 个类别\n",
      "✓ Base: 3 个类别\n",
      "✓ Aryl halide: 15 个类别\n",
      "✓ 特征矩阵形状: (3955, 4)\n",
      "✓ 目标变量形状: (3955,)\n",
      "\n",
      "✓ 训练集大小: (3164, 4)\n",
      "✓ 测试集大小: (791, 4)\n",
      "\n",
      "特征统计信息:\n",
      "特征维度: 4\n",
      "样本数量: 3955\n",
      "收率范围: 0.0% - 100.0%\n"
     ]
    }
   ],
   "source": [
    "def preprocess_features(df):\n",
    "    \"\"\"\n",
    "    处理特征缩放和预处理\n",
    "    \"\"\"\n",
    "    # 创建副本避免修改原始数据\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # 分离数值特征和分类特征\n",
    "    numeric_features = []\n",
    "    categorical_features = []\n",
    "    \n",
    "    for col in df_processed.columns:\n",
    "        if col == 'Target':  # 跳过目标变量\n",
    "            continue\n",
    "        if df_processed[col].dtype in ['int64', 'float64']:\n",
    "            numeric_features.append(col)\n",
    "        else:\n",
    "            categorical_features.append(col)\n",
    "    \n",
    "    print(f\"数值特征 ({len(numeric_features)}): {numeric_features}\")\n",
    "    print(f\"分类特征 ({len(categorical_features)}): {categorical_features}\")\n",
    "    \n",
    "    # 处理分类特征\n",
    "    label_encoders = {}\n",
    "    for col in categorical_features:\n",
    "        le = LabelEncoder()\n",
    "        df_processed[col] = le.fit_transform(df_processed[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "        print(f\"✓ {col}: {len(le.classes_)} 个类别\")\n",
    "    \n",
    "    # 准备特征矩阵\n",
    "    feature_columns = numeric_features + categorical_features\n",
    "    X = df_processed[feature_columns].values\n",
    "    y = df_processed['Target'].values if 'Target' in df_processed.columns else None\n",
    "    \n",
    "    # 标准化特征\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    print(f\"✓ 特征矩阵形状: {X_scaled.shape}\")\n",
    "    if y is not None:\n",
    "        print(f\"✓ 目标变量形状: {y.shape}\")\n",
    "    \n",
    "    return X_scaled, y, scaler, label_encoders, feature_columns\n",
    "\n",
    "# 如果数据已加载，进行预处理\n",
    "if doyle_data is not None:\n",
    "    X, y, scaler, encoders, feature_names = preprocess_features(doyle_data)\n",
    "    \n",
    "    # 划分训练测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=MAIN_SEED\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✓ 训练集大小: {X_train.shape}\")\n",
    "    print(f\"✓ 测试集大小: {X_test.shape}\")\n",
    "    \n",
    "    # 显示特征统计\n",
    "    print(f\"\\n特征统计信息:\")\n",
    "    print(f\"特征维度: {X.shape[1]}\")\n",
    "    print(f\"样本数量: {X.shape[0]}\")\n",
    "    print(f\"收率范围: {y.min():.1f}% - {y.max():.1f}%\")\n",
    "\n",
    "plt.title('Acquisition Function Comparison') # 原为中文\n",
    "plt.xlabel('Iteration') # 原为中文\n",
    "plt.ylabel('Acquisition Value') # 原为中文"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dee36e",
   "metadata": {},
   "source": [
    "## 4. 高斯过程回归器实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f38cd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始训练数据大小: (3164, 4)\n",
      "开始优化的GPR训练...\n",
      "⚠ 训练数据过大(3164)，随机采样800个样本以提高效率\n",
      "比较不同核函数的GPR性能 (优化版本):\n",
      "--------------------------------------------------\n",
      "\n",
      "训练 RBF 核函数...\n",
      "✓ 使用RBF核函数\n",
      "  使用 800 个训练样本\n",
      "✓ RBF:\n",
      "  训练 R²: 1.0000, 测试 R²: 0.2944\n",
      "  训练 MAE: 0.03, 测试 MAE: 18.24\n",
      "  训练 RMSE: 0.04, 测试 RMSE: 22.78\n",
      "  平均预测不确定性: 23.29\n",
      "\n",
      "训练 RBF + White 核函数...\n",
      "✓ 使用RBF + WhiteKernel核函数\n",
      "  使用 800 个训练样本\n",
      "✓ RBF:\n",
      "  训练 R²: 1.0000, 测试 R²: 0.2944\n",
      "  训练 MAE: 0.03, 测试 MAE: 18.24\n",
      "  训练 RMSE: 0.04, 测试 RMSE: 22.78\n",
      "  平均预测不确定性: 23.29\n",
      "\n",
      "训练 RBF + White 核函数...\n",
      "✓ 使用RBF + WhiteKernel核函数\n",
      "  使用 800 个训练样本\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 142\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m开始优化的GPR训练...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m# 使用优化版本的核函数比较\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     gpr_results = \u001b[43mcompare_gpr_kernels_optimized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m800\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gpr_results:\n\u001b[32m    145\u001b[39m         \u001b[38;5;66;03m# 选择最佳模型\u001b[39;00m\n\u001b[32m    146\u001b[39m         best_kernel = \u001b[38;5;28mmax\u001b[39m(gpr_results.keys(), key=\u001b[38;5;28;01mlambda\u001b[39;00m k: gpr_results[k][\u001b[33m'\u001b[39m\u001b[33mtest_r2\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mcompare_gpr_kernels_optimized\u001b[39m\u001b[34m(X_train, y_train, X_test, y_test, max_samples)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# 训练时使用子采样数据\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  使用 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_train_sub)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m 个训练样本\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[43mgpr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_sub\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# 预测\u001b[39;00m\n\u001b[32m     70\u001b[39m y_pred_train, y_std_train = gpr.predict(X_train_sub, return_std=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/sum/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/sum/lib/python3.12/site-packages/sklearn/gaussian_process/_gpr.py:329\u001b[39m, in \u001b[36mGaussianProcessRegressor.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.n_restarts_optimizer):\n\u001b[32m    327\u001b[39m         theta_initial = \u001b[38;5;28mself\u001b[39m._rng.uniform(bounds[:, \u001b[32m0\u001b[39m], bounds[:, \u001b[32m1\u001b[39m])\n\u001b[32m    328\u001b[39m         optima.append(\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_constrained_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta_initial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m         )\n\u001b[32m    331\u001b[39m \u001b[38;5;66;03m# Select result from run with minimal (negative) log-marginal\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[38;5;66;03m# likelihood\u001b[39;00m\n\u001b[32m    333\u001b[39m lml_values = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(itemgetter(\u001b[32m1\u001b[39m), optima))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/sum/lib/python3.12/site-packages/sklearn/gaussian_process/_gpr.py:656\u001b[39m, in \u001b[36mGaussianProcessRegressor._constrained_optimization\u001b[39m\u001b[34m(self, obj_func, initial_theta, bounds)\u001b[39m\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_constrained_optimization\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj_func, initial_theta, bounds):\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.optimizer == \u001b[33m\"\u001b[39m\u001b[33mfmin_l_bfgs_b\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         opt_res = \u001b[43mscipy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m.\u001b[49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m            \u001b[49m\u001b[43minitial_theta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mL-BFGS-B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m            \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    663\u001b[39m         _check_optimize_result(\u001b[33m\"\u001b[39m\u001b[33mlbfgs\u001b[39m\u001b[33m\"\u001b[39m, opt_res)\n\u001b[32m    664\u001b[39m         theta_opt, func_min = opt_res.x, opt_res.fun\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/sum/lib/python3.12/site-packages/scipy/optimize/_minimize.py:713\u001b[39m, in \u001b[36mminimize\u001b[39m\u001b[34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[39m\n\u001b[32m    710\u001b[39m     res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[32m    711\u001b[39m                              **options)\n\u001b[32m    712\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33ml-bfgs-b\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m713\u001b[39m     res = \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mtnc\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    716\u001b[39m     res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001b[32m    717\u001b[39m                         **options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/sum/lib/python3.12/site-packages/scipy/optimize/_lbfgsb_py.py:369\u001b[39m, in \u001b[36m_minimize_lbfgsb\u001b[39m\u001b[34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[39m\n\u001b[32m    363\u001b[39m task_str = task.tobytes()\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task_str.startswith(\u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[33mFG\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    365\u001b[39m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[32m    366\u001b[39m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[32m    367\u001b[39m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[32m    368\u001b[39m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     f, g = \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m task_str.startswith(\u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[33mNEW_X\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    371\u001b[39m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[32m    372\u001b[39m     n_iterations += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/sum/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:296\u001b[39m, in \u001b[36mScalarFunction.fun_and_grad\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.array_equal(x, \u001b[38;5;28mself\u001b[39m.x):\n\u001b[32m    295\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_x_impl(x)\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[38;5;28mself\u001b[39m._update_grad()\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f, \u001b[38;5;28mself\u001b[39m.g\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/sum/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:262\u001b[39m, in \u001b[36mScalarFunction._update_fun\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    261\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f_updated:\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m         \u001b[38;5;28mself\u001b[39m.f_updated = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/sum/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:163\u001b[39m, in \u001b[36mScalarFunction.__init__.<locals>.update_fun\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate_fun\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     \u001b[38;5;28mself\u001b[39m.f = \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/sum/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:145\u001b[39m, in \u001b[36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28mself\u001b[39m.nfev += \u001b[32m1\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m fx = \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isscalar(fx):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/sum/lib/python3.12/site-packages/scipy/optimize/_optimize.py:78\u001b[39m, in \u001b[36mMemoizeJac.__call__\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, *args):\n\u001b[32m     77\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/sum/lib/python3.12/site-packages/scipy/optimize/_optimize.py:72\u001b[39m, in \u001b[36mMemoizeJac._compute_if_needed\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.all(x == \u001b[38;5;28mself\u001b[39m.x) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.jac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     71\u001b[39m     \u001b[38;5;28mself\u001b[39m.x = np.asarray(x).copy()\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     fg = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28mself\u001b[39m.jac = fg[\u001b[32m1\u001b[39m]\n\u001b[32m     74\u001b[39m     \u001b[38;5;28mself\u001b[39m._value = fg[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/sum/lib/python3.12/site-packages/sklearn/gaussian_process/_gpr.py:301\u001b[39m, in \u001b[36mGaussianProcessRegressor.fit.<locals>.obj_func\u001b[39m\u001b[34m(theta, eval_gradient)\u001b[39m\n\u001b[32m    299\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobj_func\u001b[39m(theta, eval_gradient=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m         lml, grad = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlog_marginal_likelihood\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclone_kernel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    303\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    304\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m -lml, -grad\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/sum/lib/python3.12/site-packages/sklearn/gaussian_process/_gpr.py:587\u001b[39m, in \u001b[36mGaussianProcessRegressor.log_marginal_likelihood\u001b[39m\u001b[34m(self, theta, eval_gradient, clone_kernel)\u001b[39m\n\u001b[32m    585\u001b[39m K[np.diag_indices_from(K)] += \u001b[38;5;28mself\u001b[39m.alpha\n\u001b[32m    586\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m587\u001b[39m     L = \u001b[43mcholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGPR_CHOLESKY_LOWER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m np.linalg.LinAlgError:\n\u001b[32m    589\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (-np.inf, np.zeros_like(theta)) \u001b[38;5;28;01mif\u001b[39;00m eval_gradient \u001b[38;5;28;01melse\u001b[39;00m -np.inf\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/sum/lib/python3.12/site-packages/scipy/linalg/_decomp_cholesky.py:88\u001b[39m, in \u001b[36mcholesky\u001b[39m\u001b[34m(a, lower, overwrite_a, check_finite)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcholesky\u001b[39m(a, lower=\u001b[38;5;28;01mFalse\u001b[39;00m, overwrite_a=\u001b[38;5;28;01mFalse\u001b[39;00m, check_finite=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     45\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[33;03m    Compute the Cholesky decomposition of a matrix.\u001b[39;00m\n\u001b[32m     47\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     86\u001b[39m \n\u001b[32m     87\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     c, lower = \u001b[43m_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m                         \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/sum/lib/python3.12/site-packages/scipy/linalg/_decomp_cholesky.py:34\u001b[39m, in \u001b[36m_cholesky\u001b[39m\u001b[34m(a, lower, overwrite_a, clean, check_finite)\u001b[39m\n\u001b[32m     32\u001b[39m overwrite_a = overwrite_a \u001b[38;5;129;01mor\u001b[39;00m _datacopied(a1, a)\n\u001b[32m     33\u001b[39m potrf, = get_lapack_funcs((\u001b[33m'\u001b[39m\u001b[33mpotrf\u001b[39m\u001b[33m'\u001b[39m,), (a1,))\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m c, info = \u001b[43mpotrf\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m info > \u001b[32m0\u001b[39m:\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m-th leading minor of the array is not positive \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     37\u001b[39m                       \u001b[33m\"\u001b[39m\u001b[33mdefinite\u001b[39m\u001b[33m\"\u001b[39m % info)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def implement_gaussian_process_regressor(kernel_type='rbf', random_state=MAIN_SEED):\n",
    "    \"\"\"\n",
    "    使用适当核函数实现高斯过程回归器（优化版本）\n",
    "    \"\"\"\n",
    "    if kernel_type == 'rbf':\n",
    "        # RBF核函数 - 缩小参数搜索范围\n",
    "        kernel = ConstantKernel(1.0, (0.1, 10.0)) * RBF(1.0, (0.1, 10.0))\n",
    "        print(\"✓ 使用RBF核函数\")\n",
    "    elif kernel_type == 'matern':\n",
    "        # Matern核函数\n",
    "        kernel = ConstantKernel(1.0, (0.1, 10.0)) * Matern(length_scale=1.0, nu=1.5)\n",
    "        print(\"✓ 使用Matern核函数\")\n",
    "    elif kernel_type == 'rbf_white':\n",
    "        # RBF + 白噪声核 - 适中的噪声水平\n",
    "        kernel = ConstantKernel(1.0, (0.1, 10.0)) * RBF(1.0, (0.1, 10.0)) + WhiteKernel(0.1, (1e-3, 1.0))\n",
    "        print(\"✓ 使用RBF + WhiteKernel核函数\")\n",
    "    else:\n",
    "        # 默认RBF\n",
    "        kernel = ConstantKernel(1.0, (0.1, 10.0)) * RBF(1.0, (0.1, 10.0))\n",
    "        print(\"✓ 使用默认RBF核函数\")\n",
    "    \n",
    "    # 创建高斯过程回归器 - 优化参数设置\n",
    "    gpr = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        alpha=1e-3,  # 增加数值稳定性\n",
    "        normalize_y=True,\n",
    "        n_restarts_optimizer=3,  # 减少重启次数加快训练\n",
    "        random_state=random_state,\n",
    "        optimizer='fmin_l_bfgs_b'  # 明确指定优化器\n",
    "    )\n",
    "    \n",
    "    return gpr\n",
    "\n",
    "def compare_gpr_kernels_optimized(X_train, y_train, X_test, y_test, max_samples=1000):\n",
    "    \"\"\"\n",
    "    比较不同核函数的高斯过程回归器性能（优化版本）\n",
    "    \"\"\"\n",
    "    # 如果训练数据太大，进行子采样\n",
    "    if len(X_train) > max_samples:\n",
    "        print(f\"⚠ 训练数据过大({len(X_train)})，随机采样{max_samples}个样本以提高效率\")\n",
    "        indices = np.random.choice(len(X_train), max_samples, replace=False)\n",
    "        X_train_sub = X_train[indices]\n",
    "        y_train_sub = y_train[indices]\n",
    "    else:\n",
    "        X_train_sub = X_train\n",
    "        y_train_sub = y_train\n",
    "    \n",
    "    kernels = {\n",
    "        'RBF': 'rbf',\n",
    "        'RBF + White': 'rbf_white'  # 只测试两个最常用的核函数\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    print(\"比较不同核函数的GPR性能 (优化版本):\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for name, kernel_type in kernels.items():\n",
    "        print(f\"\\n训练 {name} 核函数...\")\n",
    "        \n",
    "        try:\n",
    "            # 创建和训练模型\n",
    "            gpr = implement_gaussian_process_regressor(kernel_type)\n",
    "            \n",
    "            # 训练时使用子采样数据\n",
    "            print(f\"  使用 {len(X_train_sub)} 个训练样本\")\n",
    "            gpr.fit(X_train_sub, y_train_sub)\n",
    "            \n",
    "            # 预测\n",
    "            y_pred_train, y_std_train = gpr.predict(X_train_sub, return_std=True)\n",
    "            y_pred_test, y_std_test = gpr.predict(X_test, return_std=True)\n",
    "            \n",
    "            # 计算指标\n",
    "            train_r2 = r2_score(y_train_sub, y_pred_train)\n",
    "            test_r2 = r2_score(y_test, y_pred_test)\n",
    "            train_mae = mean_absolute_error(y_train_sub, y_pred_train)\n",
    "            test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "            train_rmse = np.sqrt(mean_squared_error(y_train_sub, y_pred_train))\n",
    "            test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "            \n",
    "            results[name] = {\n",
    "                'model': gpr,\n",
    "                'train_r2': train_r2,\n",
    "                'test_r2': test_r2,\n",
    "                'train_mae': train_mae,\n",
    "                'test_mae': test_mae,\n",
    "                'train_rmse': train_rmse,\n",
    "                'test_rmse': test_rmse,\n",
    "                'mean_std': np.mean(y_std_test)\n",
    "            }\n",
    "            \n",
    "            print(f\"✓ {name}:\")\n",
    "            print(f\"  训练 R²: {train_r2:.4f}, 测试 R²: {test_r2:.4f}\")\n",
    "            print(f\"  训练 MAE: {train_mae:.2f}, 测试 MAE: {test_mae:.2f}\")\n",
    "            print(f\"  训练 RMSE: {train_rmse:.2f}, 测试 RMSE: {test_rmse:.2f}\")\n",
    "            print(f\"  平均预测不确定性: {np.mean(y_std_test):.2f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ {name} 训练失败: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "def create_simple_gpr_baseline(X_train, y_train, max_samples=500):\n",
    "    \"\"\"\n",
    "    创建简单的GPR基线模型用于贝叶斯优化\n",
    "    \"\"\"\n",
    "    # 进一步减少样本数以确保快速训练\n",
    "    if len(X_train) > max_samples:\n",
    "        indices = np.random.choice(len(X_train), max_samples, replace=False)\n",
    "        X_sub = X_train[indices]\n",
    "        y_sub = y_train[indices]\n",
    "    else:\n",
    "        X_sub = X_train\n",
    "        y_sub = y_train\n",
    "    \n",
    "    print(f\"创建简化GPR模型 (使用 {len(X_sub)} 个样本)\")\n",
    "    \n",
    "    # 使用最简单的核函数配置\n",
    "    kernel = ConstantKernel(1.0) * RBF(1.0) + WhiteKernel(0.1)\n",
    "    \n",
    "    gpr = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        alpha=1e-2,  # 更大的alpha提高数值稳定性\n",
    "        normalize_y=True,\n",
    "        n_restarts_optimizer=1,  # 最少重启\n",
    "        random_state=MAIN_SEED\n",
    "    )\n",
    "    \n",
    "    gpr.fit(X_sub, y_sub)\n",
    "    print(\"✓ 简化GPR模型训练完成\")\n",
    "    \n",
    "    return gpr\n",
    "\n",
    "# 如果数据已准备好，比较不同核函数\n",
    "if 'X_train' in locals():\n",
    "    print(f\"原始训练数据大小: {X_train.shape}\")\n",
    "    print(\"开始优化的GPR训练...\")\n",
    "    \n",
    "    try:\n",
    "        # 使用优化版本的核函数比较\n",
    "        gpr_results = compare_gpr_kernels_optimized(X_train, y_train, X_test, y_test, max_samples=800)\n",
    "        \n",
    "        if gpr_results:\n",
    "            # 选择最佳模型\n",
    "            best_kernel = max(gpr_results.keys(), key=lambda k: gpr_results[k]['test_r2'])\n",
    "            best_gpr = gpr_results[best_kernel]['model']\n",
    "            \n",
    "            print(f\"\\n✓ 最佳核函数: {best_kernel}\")\n",
    "            print(f\"✓ 最佳测试R²: {gpr_results[best_kernel]['test_r2']:.4f}\")\n",
    "            \n",
    "            # 可视化核函数比较\n",
    "            if len(gpr_results) > 1:\n",
    "                metrics = ['test_r2', 'test_mae', 'test_rmse']\n",
    "                metric_names = ['测试R²', '测试MAE', '测试RMSE']\n",
    "                \n",
    "                fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                \n",
    "                for i, (metric, name) in enumerate(zip(metrics, metric_names)):\n",
    "                    values = [gpr_results[kernel][metric] for kernel in gpr_results.keys()]\n",
    "                    axes[i].bar(gpr_results.keys(), values, alpha=0.7)\n",
    "                    axes[i].set_title(name)\n",
    "                    axes[i].set_ylabel(name)\n",
    "                    for j, v in enumerate(values):\n",
    "                        axes[i].text(j, v + 0.01 * max(values), f'{v:.3f}', ha='center')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "        else:\n",
    "            print(\"⚠ 所有核函数训练失败，创建简化基线模型\")\n",
    "            best_gpr = create_simple_gpr_baseline(X_train, y_train)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"✗ GPR训练出现问题: {str(e)}\")\n",
    "        print(\"创建简化基线模型...\")\n",
    "        best_gpr = create_simple_gpr_baseline(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8048794f",
   "metadata": {},
   "source": [
    "## 5. 获取函数实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8870820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def implement_expected_improvement(gpr_model, X_observed, y_observed, xi=0.01):\n",
    "    \"\"\"\n",
    "    实现期望改进（EI）获取函数\n",
    "    \"\"\"\n",
    "    def expected_improvement(X, xi=xi):\n",
    "        \"\"\"\n",
    "        计算期望改进值\n",
    "        \"\"\"\n",
    "        X = np.atleast_2d(X)\n",
    "        \n",
    "        # 获取预测均值和标准差\n",
    "        mu, sigma = gpr_model.predict(X, return_std=True)\n",
    "        mu = mu.reshape(-1, 1)\n",
    "        sigma = sigma.reshape(-1, 1)\n",
    "        \n",
    "        # 当前最佳观测值\n",
    "        f_max = np.max(y_observed)\n",
    "        \n",
    "        # 避免除零\n",
    "        sigma = np.maximum(sigma, 1e-9)\n",
    "        \n",
    "        # 计算改进\n",
    "        improvement = mu - f_max - xi\n",
    "        \n",
    "        # 计算期望改进\n",
    "        Z = improvement / sigma\n",
    "        ei = improvement * stats.norm.cdf(Z) + sigma * stats.norm.pdf(Z)\n",
    "        \n",
    "        return ei.flatten()\n",
    "    \n",
    "    return expected_improvement\n",
    "\n",
    "def implement_upper_confidence_bound(gpr_model, kappa=2.576):\n",
    "    \"\"\"\n",
    "    实现上置信界（UCB）获取函数\n",
    "    \"\"\"\n",
    "    def upper_confidence_bound(X, kappa=kappa):\n",
    "        \"\"\"\n",
    "        计算上置信界值\n",
    "        \"\"\"\n",
    "        X = np.atleast_2d(X)\n",
    "        \n",
    "        # 获取预测均值和标准差\n",
    "        mu, sigma = gpr_model.predict(X, return_std=True)\n",
    "        \n",
    "        # 计算UCB\n",
    "        ucb = mu + kappa * sigma\n",
    "        \n",
    "        return ucb.flatten()\n",
    "    \n",
    "    return upper_confidence_bound\n",
    "\n",
    "def visualize_acquisition_functions(gpr_model, X_observed, y_observed, X_space, \n",
    "                                  ei_func, ucb_func, title=\"acquisition functions visualization\"):\n",
    "    \"\"\"\n",
    "    可视化获取函数和高斯过程预测\n",
    "    \"\"\"\n",
    "    # 预测整个搜索空间\n",
    "    mu, sigma = gpr_model.predict(X_space, return_std=True)\n",
    "    \n",
    "    # 计算获取函数值\n",
    "    ei_values = ei_func(X_space)\n",
    "    ucb_values = ucb_func(X_space)\n",
    "    \n",
    "    # 创建图形\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 如果是多维特征空间，只显示前两个维度\n",
    "    if X_space.shape[1] >= 2:\n",
    "        x1_idx, x2_idx = 0, 1\n",
    "        \n",
    "        # GPR预测均值\n",
    "        im1 = axes[0,0].scatter(X_space[:, x1_idx], X_space[:, x2_idx], \n",
    "                               c=mu, cmap='viridis', alpha=0.6)\n",
    "        axes[0,0].scatter(X_observed[:, x1_idx], X_observed[:, x2_idx], \n",
    "                         c=y_observed, cmap='Reds', s=50, edgecolors='black')\n",
    "        axes[0,0].set_title('GPR predict Mean')\n",
    "        axes[0,0].set_xlabel(f'Feature {x1_idx+1}')\n",
    "        axes[0,0].set_ylabel(f'Feature {x2_idx+1}')\n",
    "        plt.colorbar(im1, ax=axes[0,0])\n",
    "        \n",
    "        # GPR预测不确定性\n",
    "        im2 = axes[0,1].scatter(X_space[:, x1_idx], X_space[:, x2_idx], \n",
    "                               c=sigma, cmap='plasma', alpha=0.6)\n",
    "        axes[0,1].scatter(X_observed[:, x1_idx], X_observed[:, x2_idx], \n",
    "                         c='white', s=50, edgecolors='black')\n",
    "        axes[0,1].set_title('GPR预测不确定性')\n",
    "        axes[0,1].set_xlabel(f'特征 {x1_idx+1}')\n",
    "        axes[0,1].set_ylabel(f'特征 {x2_idx+1}')\n",
    "        plt.colorbar(im2, ax=axes[0,1])\n",
    "        \n",
    "        # EI获取函数\n",
    "        im3 = axes[1,0].scatter(X_space[:, x1_idx], X_space[:, x2_idx], \n",
    "                               c=ei_values, cmap='Blues', alpha=0.6)\n",
    "        axes[1,0].scatter(X_observed[:, x1_idx], X_observed[:, x2_idx], \n",
    "                         c='red', s=50, edgecolors='black')\n",
    "        axes[1,0].set_title('Expected Improvement (EI)')\n",
    "        axes[1,0].set_xlabel(f'Feature {x1_idx+1}')\n",
    "        axes[1,0].set_ylabel(f'Feature {x2_idx+1}')\n",
    "        plt.colorbar(im3, ax=axes[1,0])\n",
    "        \n",
    "        # UCB获取函数\n",
    "        im4 = axes[1,1].scatter(X_space[:, x1_idx], X_space[:, x2_idx], \n",
    "                               c=ucb_values, cmap='Oranges', alpha=0.6)\n",
    "        axes[1,1].scatter(X_observed[:, x1_idx], X_observed[:, x2_idx], \n",
    "                         c='blue', s=50, edgecolors='black')\n",
    "        axes[1,1].set_title('Upper Confidence Bound (UCB)')\n",
    "        axes[1,1].set_xlabel(f'Feature {x1_idx+1}')\n",
    "        axes[1,1].set_ylabel(f'Feature {x2_idx+1}')\n",
    "        plt.colorbar(im4, ax=axes[1,1])\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return ei_values, ucb_values\n",
    "\n",
    "# 演示获取函数（如果有训练好的模型）\n",
    "if 'best_gpr' in locals() and 'X_train' in locals():\n",
    "    print(\"✓ 创建获取函数...\")\n",
    "    \n",
    "    # 创建获取函数\n",
    "    ei_func = implement_expected_improvement(best_gpr, X_train, y_train, xi=0.01)\n",
    "    ucb_func = implement_upper_confidence_bound(best_gpr, kappa=2.576)\n",
    "    \n",
    "    # 创建搜索空间的子集用于可视化\n",
    "    n_vis_samples = min(1000, len(X_test))\n",
    "    vis_indices = np.random.choice(len(X_test), n_vis_samples, replace=False)\n",
    "    X_vis = X_test[vis_indices]\n",
    "    \n",
    "    print(f\"✓ 在 {n_vis_samples} 个测试点上可视化获取函数...\")\n",
    "    \n",
    "    # 可视化获取函数\n",
    "    ei_vals, ucb_vals = visualize_acquisition_functions(\n",
    "        best_gpr, X_train[:50], y_train[:50], X_vis, ei_func, ucb_func\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ EI值范围: {ei_vals.min():.4f} - {ei_vals.max():.4f}\")\n",
    "    print(f\"✓ UCB值范围: {ucb_vals.min():.2f} - {ucb_vals.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec185bb1",
   "metadata": {},
   "source": [
    "## 6. 贝叶斯优化循环实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112e86de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_bayesian_optimization(X_space, y_space, n_initial=20, random_state=MAIN_SEED):\n",
    "    \"\"\"\n",
    "    初始化贝叶斯优化\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # 选择初始点\n",
    "    initial_indices = np.random.choice(len(X_space), n_initial, replace=False)\n",
    "    X_initial = X_space[initial_indices]\n",
    "    y_initial = y_space[initial_indices]\n",
    "    \n",
    "    # 剩余搜索空间\n",
    "    remaining_indices = np.setdiff1d(np.arange(len(X_space)), initial_indices)\n",
    "    X_remaining = X_space[remaining_indices]\n",
    "    y_remaining = y_space[remaining_indices]\n",
    "    \n",
    "    print(f\"✓ 初始化完成:\")\n",
    "    print(f\"  初始点数量: {len(X_initial)}\")\n",
    "    print(f\"  剩余搜索空间: {len(X_remaining)}\")\n",
    "    print(f\"  初始最佳收率: {y_initial.max():.2f}%\")\n",
    "    \n",
    "    return X_initial, y_initial, X_remaining, y_remaining, initial_indices\n",
    "\n",
    "def bayesian_optimization_loop(X_initial, y_initial, X_remaining, y_remaining, \n",
    "                             n_iterations=10, acquisition_type='ei', \n",
    "                             random_state=MAIN_SEED):\n",
    "    \"\"\"\n",
    "    实现主动学习循环进行收率优化\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # 初始化\n",
    "    X_observed = X_initial.copy()\n",
    "    y_observed = y_initial.copy()\n",
    "    optimization_history = []\n",
    "    \n",
    "    print(f\"开始贝叶斯优化循环 ({acquisition_type.upper()})...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for iteration in range(n_iterations):\n",
    "        print(f\"\\\\n第 {iteration + 1}/{n_iterations} 轮优化:\")\n",
    "        \n",
    "        # 训练高斯过程模型\n",
    "        gpr = implement_gaussian_process_regressor(kernel_type='rbf_white', \n",
    "                                                 random_state=random_state)\n",
    "        gpr.fit(X_observed, y_observed)\n",
    "        \n",
    "        # 创建获取函数\n",
    "        if acquisition_type == 'ei':\n",
    "            acq_func = implement_expected_improvement(gpr, X_observed, y_observed, xi=0.01)\n",
    "        else:  # ucb\n",
    "            acq_func = implement_upper_confidence_bound(gpr, kappa=2.576)\n",
    "        \n",
    "        # 在剩余空间中评估获取函数\n",
    "        if len(X_remaining) == 0:\n",
    "            print(\"  ✗ 搜索空间已耗尽!\")\n",
    "            break\n",
    "            \n",
    "        acq_values = acq_func(X_remaining)\n",
    "        \n",
    "        # 选择最佳点\n",
    "        best_idx = np.argmax(acq_values)\n",
    "        next_X = X_remaining[best_idx:best_idx+1]\n",
    "        next_y = y_remaining[best_idx:best_idx+1]\n",
    "        \n",
    "        # 更新观测数据\n",
    "        X_observed = np.vstack([X_observed, next_X])\n",
    "        y_observed = np.hstack([y_observed, next_y])\n",
    "        \n",
    "        # 从剩余空间中移除选中的点\n",
    "        X_remaining = np.delete(X_remaining, best_idx, axis=0)\n",
    "        y_remaining = np.delete(y_remaining, best_idx)\n",
    "        \n",
    "        # 记录历史\n",
    "        current_best = y_observed.max()\n",
    "        current_best_idx = y_observed.argmax()\n",
    "        \n",
    "        optimization_history.append({\n",
    "            'iteration': iteration + 1,\n",
    "            'selected_yield': next_y[0],\n",
    "            'acquisition_value': acq_values[best_idx],\n",
    "            'current_best_yield': current_best,\n",
    "            'best_yield_index': current_best_idx,\n",
    "            'total_observed': len(y_observed)\n",
    "        })\n",
    "        \n",
    "        print(f\"  选中收率: {next_y[0]:.2f}%\")\n",
    "        print(f\"  获取函数值: {acq_values[best_idx]:.4f}\")\n",
    "        print(f\"  当前最佳收率: {current_best:.2f}%\")\n",
    "        print(f\"  总观测点数: {len(y_observed)}\")\n",
    "    \n",
    "    print(f\"\\\\n✓ 贝叶斯优化完成!\")\n",
    "    print(f\"✓ 最终最佳收率: {y_observed.max():.2f}%\")\n",
    "    print(f\"✓ 总观测点数: {len(y_observed)}\")\n",
    "    \n",
    "    return X_observed, y_observed, optimization_history, gpr\n",
    "\n",
    "def compare_acquisition_functions(X_initial, y_initial, X_remaining, y_remaining, \n",
    "                                n_iterations=10):\n",
    "    \"\"\"\n",
    "    比较不同获取函数的性能\n",
    "    \"\"\"\n",
    "    acquisition_functions = ['ei', 'ucb']\n",
    "    results = {}\n",
    "    \n",
    "    print(\"比较获取函数性能:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for acq_type in acquisition_functions:\n",
    "        print(f\"\\\\n测试 {acq_type.upper()} 获取函数...\")\n",
    "        \n",
    "        # 运行贝叶斯优化\n",
    "        X_obs, y_obs, history, final_gpr = bayesian_optimization_loop(\n",
    "            X_initial.copy(), y_initial.copy(), \n",
    "            X_remaining.copy(), y_remaining.copy(),\n",
    "            n_iterations=n_iterations, \n",
    "            acquisition_type=acq_type,\n",
    "            random_state=RANDOM_SEEDS[1]  # 使用不同种子确保公平比较\n",
    "        )\n",
    "        \n",
    "        results[acq_type] = {\n",
    "            'X_observed': X_obs,\n",
    "            'y_observed': y_obs,\n",
    "            'history': history,\n",
    "            'final_gpr': final_gpr,\n",
    "            'final_best': y_obs.max(),\n",
    "            'improvement': y_obs.max() - y_initial.max()\n",
    "        }\n",
    "    \n",
    "    # 比较结果\n",
    "    print(f\"\\\\n获取函数性能比较:\")\n",
    "    print(\"-\" * 40)\n",
    "    for acq_type, result in results.items():\n",
    "        print(f\"{acq_type.upper()}:\")\n",
    "        print(f\"  最终最佳收率: {result['final_best']:.2f}%\")\n",
    "        print(f\"  相对初始改进: {result['improvement']:.2f}%\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 如果数据已准备好，运行贝叶斯优化\n",
    "if 'X_train' in locals() and 'y_train' in locals():\n",
    "    print(\"准备运行贝叶斯优化...\")\n",
    "    \n",
    "    # 初始化贝叶斯优化\n",
    "    X_init, y_init, X_remain, y_remain, init_idx = initialize_bayesian_optimization(\n",
    "        X_train, y_train, n_initial=20, random_state=MAIN_SEED\n",
    "    )\n",
    "    \n",
    "    # 比较不同获取函数\n",
    "    comparison_results = compare_acquisition_functions(\n",
    "        X_init, y_init, X_remain, y_remain, n_iterations=10\n",
    "    )\n",
    "    \n",
    "    # 选择最佳获取函数\n",
    "    best_acq = max(comparison_results.keys(), \n",
    "                   key=lambda k: comparison_results[k]['final_best'])\n",
    "    \n",
    "    print(f\"\\\\n✓ 最佳获取函数: {best_acq.upper()}\")\n",
    "    print(f\"✓ 最佳最终收率: {comparison_results[best_acq]['final_best']:.2f}%\")\n",
    "    \n",
    "    # 保存最佳结果\n",
    "    best_optimization = comparison_results[best_acq]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba5484f",
   "metadata": {},
   "source": [
    "## 7. 优化进度跟踪和收敛性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d4120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_optimization_progress(optimization_history, title=\"贝叶斯优化进度\"):\n",
    "    \"\"\"\n",
    "    跟踪优化进度和收敛性\n",
    "    \"\"\"\n",
    "    if not optimization_history:\n",
    "        print(\"✗ 没有优化历史数据\")\n",
    "        return\n",
    "        \n",
    "    # 提取数据\n",
    "    iterations = [h['iteration'] for h in optimization_history]\n",
    "    selected_yields = [h['selected_yield'] for h in optimization_history]\n",
    "    best_yields = [h['current_best_yield'] for h in optimization_history]\n",
    "    acquisition_values = [h['acquisition_value'] for h in optimization_history]\n",
    "    \n",
    "    # 创建图形\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 1. 最佳收率随迭代变化\n",
    "    axes[0,0].plot(iterations, best_yields, 'b-o', linewidth=2, markersize=6)\n",
    "    axes[0,0].set_xlabel('迭代次数')\n",
    "    axes[0,0].set_ylabel('最佳收率 (%)')\n",
    "    axes[0,0].set_title('最佳收率收敛曲线')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 添加改进量注释\n",
    "    initial_best = best_yields[0] if len(best_yields) > 0 else 0\n",
    "    final_best = best_yields[-1] if len(best_yields) > 0 else 0\n",
    "    improvement = final_best - initial_best\n",
    "    axes[0,0].text(0.02, 0.98, f'总改进: {improvement:.2f}%', \n",
    "                   transform=axes[0,0].transAxes, verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    # 2. 每次选中的收率\n",
    "    axes[0,1].bar(iterations, selected_yields, alpha=0.7, color='orange')\n",
    "    axes[0,1].axhline(y=np.mean(selected_yields), color='red', linestyle='--', \n",
    "                     label=f'平均: {np.mean(selected_yields):.2f}%')\n",
    "    axes[0,1].set_xlabel('迭代次数')\n",
    "    axes[0,1].set_ylabel('选中收率 (%)')\n",
    "    axes[0,1].set_title('每轮选中的收率')\n",
    "    axes[0,1].legend()\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. 获取函数值变化\n",
    "    axes[1,0].plot(iterations, acquisition_values, 'g-s', linewidth=2, markersize=6)\n",
    "    axes[1,0].set_xlabel('迭代次数')\n",
    "    axes[1,0].set_ylabel('获取函数值')\n",
    "    axes[1,0].set_title('获取函数值变化')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. 收敛性分析 - 改进率\n",
    "    improvements = np.diff([initial_best] + best_yields)\n",
    "    axes[1,1].bar(iterations, improvements, alpha=0.7, color='purple')\n",
    "    axes[1,1].axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "    axes[1,1].set_xlabel('迭代次数')\n",
    "    axes[1,1].set_ylabel('收率改进 (%)')\n",
    "    axes[1,1].set_title('每轮收率改进')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 打印统计信息\n",
    "    print(f\"优化进度统计:\")\n",
    "    print(f\"  初始最佳收率: {initial_best:.2f}%\")\n",
    "    print(f\"  最终最佳收率: {final_best:.2f}%\")\n",
    "    print(f\"  总改进: {improvement:.2f}%\")\n",
    "    print(f\"  平均每轮改进: {improvement/len(iterations):.3f}%\")\n",
    "    print(f\"  最大单轮改进: {max(improvements):.2f}%\")\n",
    "    print(f\"  改进轮数: {sum(1 for imp in improvements if imp > 0)}/{len(improvements)}\")\n",
    "    \n",
    "    return {\n",
    "        'initial_best': initial_best,\n",
    "        'final_best': final_best,\n",
    "        'total_improvement': improvement,\n",
    "        'avg_improvement_per_iteration': improvement/len(iterations),\n",
    "        'max_single_improvement': max(improvements),\n",
    "        'improvement_iterations': sum(1 for imp in improvements if imp > 0)\n",
    "    }\n",
    "\n",
    "def analyze_convergence(optimization_history, window_size=3):\n",
    "    \"\"\"\n",
    "    分析优化收敛性\n",
    "    \"\"\"\n",
    "    if len(optimization_history) < window_size:\n",
    "        print(f\"✗ 优化历史太短，需要至少 {window_size} 轮迭代\")\n",
    "        return\n",
    "        \n",
    "    best_yields = [h['current_best_yield'] for h in optimization_history]\n",
    "    \n",
    "    # 计算滑动窗口内的改进\n",
    "    recent_improvements = []\n",
    "    for i in range(window_size, len(best_yields)):\n",
    "        recent_improvement = best_yields[i] - best_yields[i-window_size]\n",
    "        recent_improvements.append(recent_improvement)\n",
    "    \n",
    "    # 收敛判断\n",
    "    convergence_threshold = 0.1  # 0.1% 收率改进阈值\n",
    "    is_converged = len(recent_improvements) > 0 and all(\n",
    "        imp < convergence_threshold for imp in recent_improvements[-window_size:]\n",
    "    )\n",
    "    \n",
    "    print(f\"收敛性分析 (窗口大小: {window_size}):\")\n",
    "    print(f\"  收敛阈值: {convergence_threshold}%\")\n",
    "    print(f\"  最近 {window_size} 轮改进: {recent_improvements[-window_size:] if recent_improvements else '无'}\")\n",
    "    print(f\"  是否收敛: {'是' if is_converged else '否'}\")\n",
    "    \n",
    "    if recent_improvements:\n",
    "        avg_recent_improvement = np.mean(recent_improvements[-window_size:])\n",
    "        print(f\"  最近平均改进: {avg_recent_improvement:.3f}%\")\n",
    "    \n",
    "    return is_converged\n",
    "\n",
    "# 如果有优化结果，分析进度\n",
    "if 'comparison_results' in locals():\n",
    "    print(\"分析优化进度...\")\n",
    "    \n",
    "    for acq_type, result in comparison_results.items():\n",
    "        print(f\"\\\\n{acq_type.upper()} 获取函数结果:\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        # 跟踪进度\n",
    "        progress_stats = track_optimization_progress(\n",
    "            result['history'], \n",
    "            title=f\"{acq_type.upper()} 贝叶斯优化进度\"\n",
    "        )\n",
    "        \n",
    "        # 分析收敛性\n",
    "        convergence_status = analyze_convergence(result['history'])\n",
    "        \n",
    "        print(f\"\\\\n{acq_type.upper()} 最终统计:\")\n",
    "        print(f\"  最佳收率: {result['final_best']:.2f}%\")\n",
    "        print(f\"  总改进: {result['improvement']:.2f}%\")\n",
    "        print(f\"  是否收敛: {'是' if convergence_status else '否'}\")\n",
    "    \n",
    "    # 比较不同获取函数的性能\n",
    "    print(f\"\\\\n获取函数性能对比:\")\n",
    "    print(\"-\" * 50)\n",
    "    acq_performance = []\n",
    "    for acq_type, result in comparison_results.items():\n",
    "        acq_performance.append({\n",
    "            'method': acq_type.upper(),\n",
    "            'final_best': result['final_best'],\n",
    "            'improvement': result['improvement']\n",
    "        })\n",
    "    \n",
    "    # 按最终最佳收率排序\n",
    "    acq_performance.sort(key=lambda x: x['final_best'], reverse=True)\n",
    "    \n",
    "    for i, perf in enumerate(acq_performance):\n",
    "        rank = \"🥇\" if i == 0 else \"🥈\" if i == 1 else \"🥉\"\n",
    "        print(f\"{rank} {perf['method']}: {perf['final_best']:.2f}% (改进 {perf['improvement']:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff50a4c",
   "metadata": {},
   "source": [
    "## 8. 最优反应条件分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4c8743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_optimal_conditions(X_observed, y_observed, scaler, encoders, \n",
    "                              feature_names, top_n=5):\n",
    "    \"\"\"\n",
    "    分析发现的最优反应条件\n",
    "    \"\"\"\n",
    "    # 找到最佳收率的点\n",
    "    best_idx = np.argmax(y_observed)\n",
    "    best_yield = y_observed[best_idx]\n",
    "    best_features = X_observed[best_idx].reshape(1, -1)\n",
    "    \n",
    "    print(f\"最优反应条件分析:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"最佳收率: {best_yield:.2f}%\")\n",
    "    print(f\"最佳条件在第 {best_idx + 1} 个观测点发现\")\n",
    "    \n",
    "    # 反向变换特征以获得原始值\n",
    "    best_features_original = scaler.inverse_transform(best_features)[0]\n",
    "    \n",
    "    print(f\"\\\\n最佳反应条件参数:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    for i, (feature_name, value) in enumerate(zip(feature_names, best_features_original)):\n",
    "        if feature_name in encoders:\n",
    "            # 分类特征，反向编码\n",
    "            try:\n",
    "                # 将连续值转换为最接近的整数索引\n",
    "                class_idx = int(round(value))\n",
    "                if 0 <= class_idx < len(encoders[feature_name].classes_):\n",
    "                    original_value = encoders[feature_name].classes_[class_idx]\n",
    "                else:\n",
    "                    original_value = f\"索引 {class_idx} (超出范围)\"\n",
    "                print(f\"  {feature_name}: {original_value}\")\n",
    "            except:\n",
    "                print(f\"  {feature_name}: {value:.3f} (解码失败)\")\n",
    "        else:\n",
    "            # 数值特征\n",
    "            print(f\"  {feature_name}: {value:.3f}\")\n",
    "    \n",
    "    # 分析前N个最佳条件\n",
    "    print(f\"\\\\n前 {top_n} 个最佳反应条件:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    top_indices = np.argsort(y_observed)[-top_n:][::-1]  # 从高到低排序\n",
    "    \n",
    "    top_conditions = []\n",
    "    for rank, idx in enumerate(top_indices, 1):\n",
    "        yield_val = y_observed[idx]\n",
    "        features_scaled = X_observed[idx].reshape(1, -1)\n",
    "        features_original = scaler.inverse_transform(features_scaled)[0]\n",
    "        \n",
    "        condition = {\n",
    "            'rank': rank,\n",
    "            'yield': yield_val,\n",
    "            'index': idx,\n",
    "            'features': {}\n",
    "        }\n",
    "        \n",
    "        print(f\"\\\\n第 {rank} 名: 收率 {yield_val:.2f}%\")\n",
    "        \n",
    "        for i, (feature_name, value) in enumerate(zip(feature_names, features_original)):\n",
    "            if feature_name in encoders:\n",
    "                try:\n",
    "                    class_idx = int(round(value))\n",
    "                    if 0 <= class_idx < len(encoders[feature_name].classes_):\n",
    "                        original_value = encoders[feature_name].classes_[class_idx]\n",
    "                        condition['features'][feature_name] = original_value\n",
    "                        print(f\"    {feature_name}: {original_value}\")\n",
    "                    else:\n",
    "                        condition['features'][feature_name] = f\"索引 {class_idx}\"\n",
    "                        print(f\"    {feature_name}: 索引 {class_idx}\")\n",
    "                except:\n",
    "                    condition['features'][feature_name] = value\n",
    "                    print(f\"    {feature_name}: {value:.3f}\")\n",
    "            else:\n",
    "                condition['features'][feature_name] = value\n",
    "                print(f\"    {feature_name}: {value:.3f}\")\n",
    "        \n",
    "        top_conditions.append(condition)\n",
    "    \n",
    "    return {\n",
    "        'best_yield': best_yield,\n",
    "        'best_index': best_idx,\n",
    "        'best_features': best_features_original,\n",
    "        'top_conditions': top_conditions\n",
    "    }\n",
    "\n",
    "def chemical_interpretation(optimization_results, feature_names):\n",
    "    \"\"\"\n",
    "    提供化学意义的解释\n",
    "    \"\"\"\n",
    "    print(f\"\\\\n化学解释和见解:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    top_conditions = optimization_results['top_conditions']\n",
    "    \n",
    "    # 分析常见的最优特征\n",
    "    feature_frequency = {}\n",
    "    for condition in top_conditions:\n",
    "        for feature_name, value in condition['features'].items():\n",
    "            if feature_name not in feature_frequency:\n",
    "                feature_frequency[feature_name] = {}\n",
    "            if str(value) not in feature_frequency[feature_name]:\n",
    "                feature_frequency[feature_name][str(value)] = 0\n",
    "            feature_frequency[feature_name][str(value)] += 1\n",
    "    \n",
    "    print(\"\\\\n最优条件中的常见特征:\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    for feature_name, value_counts in feature_frequency.items():\n",
    "        print(f\"\\\\n{feature_name}:\")\n",
    "        sorted_values = sorted(value_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        for value, count in sorted_values:\n",
    "            percentage = (count / len(top_conditions)) * 100\n",
    "            print(f\"  {value}: {count}/{len(top_conditions)} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # 化学见解\n",
    "    print(f\"\\\\n化学见解:\")\n",
    "    print(\"-\" * 20)\n",
    "    \n",
    "    best_yield = optimization_results['best_yield']\n",
    "    \n",
    "    if best_yield > 90:\n",
    "        print(\"✓ 发现了优秀的反应条件 (>90% 收率)\")\n",
    "        print(\"  - 这些条件可能代表了该反应体系的近最优参数\")\n",
    "        print(\"  - 建议在实验室中验证这些高收率条件\")\n",
    "    elif best_yield > 70:\n",
    "        print(\"✓ 发现了良好的反应条件 (70-90% 收率)\")\n",
    "        print(\"  - 这些条件显示了合理的反应效率\")\n",
    "        print(\"  - 可能还有进一步优化的空间\")\n",
    "    else:\n",
    "        print(\"⚠ 发现的最佳条件收率较低 (<70%)\")\n",
    "        print(\"  - 可能需要考虑其他反应参数或条件\")\n",
    "        print(\"  - 建议扩大搜索空间或尝试不同的优化策略\")\n",
    "    \n",
    "    print(f\"\\\\n贝叶斯优化的优势:\")\n",
    "    print(\"- 高效的搜索策略，避免了穷举所有可能的组合\")\n",
    "    print(\"- 通过不确定性量化指导实验设计\")\n",
    "    print(\"- 在有限的实验预算下最大化发现最优条件的概率\")\n",
    "    \n",
    "    return feature_frequency\n",
    "\n",
    "# 如果有最佳优化结果，进行条件分析\n",
    "if 'best_optimization' in locals() and 'scaler' in locals():\n",
    "    print(\"分析最优反应条件...\")\n",
    "    \n",
    "    # 分析最优条件\n",
    "    optimal_analysis = analyze_optimal_conditions(\n",
    "        best_optimization['X_observed'],\n",
    "        best_optimization['y_observed'],\n",
    "        scaler,\n",
    "        encoders,\n",
    "        feature_names,\n",
    "        top_n=5\n",
    "    )\n",
    "    \n",
    "    # 化学解释\n",
    "    chemical_insights = chemical_interpretation(optimal_analysis, feature_names)\n",
    "    \n",
    "    # 保存结果\n",
    "    print(f\"\\\\n✓ 最优条件分析完成\")\n",
    "    print(f\"✓ 最佳发现收率: {optimal_analysis['best_yield']:.2f}%\")\n",
    "    print(f\"✓ 分析了前 {len(optimal_analysis['top_conditions'])} 个最佳条件\")\n",
    "else:\n",
    "    print(\"⚠ 需要先运行贝叶斯优化以获得结果\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed621aa",
   "metadata": {},
   "source": [
    "## 9. 结果保存和总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b695841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_optimization_results(comparison_results, optimal_analysis, \n",
    "                            chemical_insights, save_dir='results'):\n",
    "    \"\"\"\n",
    "    保存贝叶斯优化结果\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    # 创建结果目录\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. 保存获取函数比较结果\n",
    "    acq_comparison = []\n",
    "    for acq_type, result in comparison_results.items():\n",
    "        acq_comparison.append({\n",
    "            'acquisition_function': acq_type.upper(),\n",
    "            'final_best_yield': result['final_best'],\n",
    "            'improvement': result['improvement'],\n",
    "            'total_observations': len(result['y_observed'])\n",
    "        })\n",
    "    \n",
    "    acq_df = pd.DataFrame(acq_comparison)\n",
    "    acq_df.to_csv(f'{save_dir}/problem3_acquisition_comparison.csv', index=False)\n",
    "    print(f\"✓ 获取函数比较结果已保存到 {save_dir}/problem3_acquisition_comparison.csv\")\n",
    "    \n",
    "    # 2. 保存最优条件详情\n",
    "    if optimal_analysis:\n",
    "        optimal_conditions = []\n",
    "        for condition in optimal_analysis['top_conditions']:\n",
    "            condition_dict = {\n",
    "                'rank': condition['rank'],\n",
    "                'yield': condition['yield'],\n",
    "                'observation_index': condition['index']\n",
    "            }\n",
    "            # 添加特征信息\n",
    "            for feature_name, value in condition['features'].items():\n",
    "                condition_dict[feature_name] = value\n",
    "            optimal_conditions.append(condition_dict)\n",
    "        \n",
    "        optimal_df = pd.DataFrame(optimal_conditions)\n",
    "        optimal_df.to_csv(f'{save_dir}/problem3_optimal_conditions.csv', index=False)\n",
    "        print(f\"✓ 最优条件已保存到 {save_dir}/problem3_optimal_conditions.csv\")\n",
    "    \n",
    "    # 3. 保存优化历史\n",
    "    best_acq = max(comparison_results.keys(), \n",
    "                   key=lambda k: comparison_results[k]['final_best'])\n",
    "    best_history = comparison_results[best_acq]['history']\n",
    "    \n",
    "    history_df = pd.DataFrame(best_history)\n",
    "    history_df.to_csv(f'{save_dir}/problem3_optimization_history.csv', index=False)\n",
    "    print(f\"✓ 优化历史已保存到 {save_dir}/problem3_optimization_history.csv\")\n",
    "    \n",
    "    # 4. 保存综合结果报告\n",
    "    summary = {\n",
    "        'student_id': 153,\n",
    "        'random_seeds': RANDOM_SEEDS,\n",
    "        'dataset': 'Reaction Dataset B (Doyle)',\n",
    "        'optimization_method': 'Bayesian Optimization',\n",
    "        'best_acquisition_function': best_acq.upper(),\n",
    "        'best_yield_found': comparison_results[best_acq]['final_best'],\n",
    "        'total_improvement': comparison_results[best_acq]['improvement'],\n",
    "        'optimization_iterations': len(best_history),\n",
    "        'initial_observations': 20,\n",
    "        'total_observations': len(comparison_results[best_acq]['y_observed'])\n",
    "    }\n",
    "    \n",
    "    summary_df = pd.DataFrame([summary])\n",
    "    summary_df.to_csv(f'{save_dir}/problem3_summary.csv', index=False)\n",
    "    print(f\"✓ 综合报告已保存到 {save_dir}/problem3_summary.csv\")\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def create_final_summary():\n",
    "    \"\"\"\n",
    "    创建最终总结报告\n",
    "    \"\"\"\n",
    "    print(\"\\\\n\" + \"=\"*60)\n",
    "    print(\"Problem 3: 贝叶斯优化反应收率预测 - 最终总结\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if 'comparison_results' in locals() and 'optimal_analysis' in locals():\n",
    "        best_acq = max(comparison_results.keys(), \n",
    "                       key=lambda k: comparison_results[k]['final_best'])\n",
    "        best_result = comparison_results[best_acq]\n",
    "        \n",
    "        print(f\"\\\\n🎯 核心成果:\")\n",
    "        print(f\"   最佳获取函数: {best_acq.upper()}\")\n",
    "        print(f\"   发现最高收率: {best_result['final_best']:.2f}%\")\n",
    "        print(f\"   相对初始改进: {best_result['improvement']:.2f}%\")\n",
    "        \n",
    "        print(f\"\\\\n📊 优化效率:\")\n",
    "        print(f\"   初始观测点: 20 个\")\n",
    "        print(f\"   优化迭代: {len(best_result['history'])} 轮\")\n",
    "        print(f\"   总观测点: {len(best_result['y_observed'])} 个\")\n",
    "        \n",
    "        print(f\"\\\\n🔬 方法学优势:\")\n",
    "        print(\"   ✓ 高斯过程提供预测不确定性量化\")\n",
    "        print(\"   ✓ 获取函数指导智能样本选择\")\n",
    "        print(\"   ✓ 贝叶斯框架平衡探索与利用\")\n",
    "        print(\"   ✓ 相比随机搜索显著提高效率\")\n",
    "        \n",
    "        print(f\"\\\\n🧪 化学见解:\")\n",
    "        if best_result['final_best'] > 90:\n",
    "            print(\"   ✓ 发现了高效反应条件 (>90% 收率)\")\n",
    "            print(\"   ✓ 条件组合具有良好的可重复性潜力\")\n",
    "        elif best_result['final_best'] > 70:\n",
    "            print(\"   ✓ 发现了可接受的反应条件 (70-90% 收率)\")\n",
    "            print(\"   ✓ 为进一步优化提供了良好基础\")\n",
    "        else:\n",
    "            print(\"   ⚠ 最佳条件收率有待提高 (<70%)\")\n",
    "            print(\"   ⚠ 可能需要探索更广泛的参数空间\")\n",
    "        \n",
    "        print(f\"\\\\n📈 技术贡献:\")\n",
    "        print(\"   - 展示了贝叶斯优化在化学反应优化中的应用\")\n",
    "        print(\"   - 比较了不同获取函数的性能差异\")\n",
    "        print(\"   - 提供了化学反应条件的定量优化方法\")\n",
    "        print(\"   - 为实验设计提供了智能化决策支持\")\n",
    "        \n",
    "        # 如果有保存结果的函数可用\n",
    "        if 'optimal_analysis' in locals():\n",
    "            saved_summary = save_optimization_results(\n",
    "                comparison_results, optimal_analysis, \n",
    "                chemical_insights if 'chemical_insights' in locals() else None\n",
    "            )\n",
    "            print(f\"\\\\n💾 结果文件:\")\n",
    "            print(\"   ✓ 所有结果已保存到 results/ 目录\")\n",
    "            print(\"   ✓ 包含详细的优化历史和最优条件\")\n",
    "    else:\n",
    "        print(\"\\\\n⚠ 请先运行完整的贝叶斯优化流程\")\n",
    "        print(\"   需要执行前面的所有代码单元以获得结果\")\n",
    "    \n",
    "    print(f\"\\\\n🎓 学习成果:\")\n",
    "    print(\"   - 掌握了高斯过程回归的实现和应用\")\n",
    "    print(\"   - 理解了不同获取函数的设计原理\")\n",
    "    print(\"   - 学会了贝叶斯优化的完整实现流程\")\n",
    "    print(\"   - 培养了化学数据分析和解释能力\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*60)\n",
    "    print(\"Problem 3 完成！🎉\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# 创建最终总结\n",
    "create_final_summary()\n",
    "\n",
    "print(f\"\\\\n📝 使用说明:\")\n",
    "print(\"1. 确保已安装所需的Python库 (pandas, numpy, scikit-learn, rdkit等)\")\n",
    "print(\"2. 将反应数据集B放置在正确的路径下\")\n",
    "print(\"3. 按顺序执行所有代码单元\")\n",
    "print(\"4. 查看results/目录下的保存结果\")\n",
    "print(\"5. 根据化学见解指导实际实验设计\")\n",
    "\n",
    "plt.title('Best Yield per Iteration') # 原为中文\n",
    "plt.xlabel('Iteration') # 原为中文\n",
    "plt.ylabel('Best Yield') # 原为中文"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
